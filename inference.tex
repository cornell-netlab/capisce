\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm, array, stmaryrd}
\usepackage{wasysym}
\usepackage{booktabs}
\usepackage{todonotes}
\usepackage{float}
\usepackage{scalerel}
%% \usepackage[notext,not1,nomath]{stix}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{soul}

\title{Notes on Control Plane Inference}
\author{Eric Campbell}


% semantics
\newcommand{\pkt}{\mathit{pkt}}
\newcommand{\error}{\mathsf{error}}
\newcommand{\denote}[1]{\left\llbracket#1\right\rrbracket}
\newcommand{\edenote}[1]{\mathcal{E}\denote{#1}}

%booleans
\newcommand{\TRUE}{\mathsf{tt}}
\newcommand{\FALSE}{\mathsf{ff}}

%% bitvectors
\newcommand{\binop}{\mathbin{\oplus}}
\newcommand{\unop}{\mathop{\text{\pointer}}}

% sets
\newcommand{\Value}{\mathsf{Value}}
\newcommand{\BVExpr}{\mathsf{BVExpr}}
\newcommand{\BExpr}{\mathsf{BExpr}}
\newcommand{\Cmd}{\mathsf{Cmd}}
\newcommand{\Action}{\mathsf{Action}}
\newcommand{\Instr}{\mathsf{Instr}}
\newcommand{\Prog}{\mathsf{Prog}}
\newcommand{\GCL}{\mathsf{GCL}}
\newcommand{\Pkt}{\mathsf{Pkt}}
\newcommand{\Model}{\mathsf{Model}}
\newcommand{\Hdr}{\mathsf{Hdr}}
\newcommand{\Field}{\mathsf{Field}}
\newcommand{\Table}{\mathsf{Table}}
\newcommand{\Row}{\mathsf{Row}}
\newcommand{\List}{\mathsf{List}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\SymbRow}{\mathsf{SymbRow}}
\newcommand{\State}{\mathsf{State}}

% record fields
\newcommand{\matches}{\mathsf{matches}}
\newcommand{\action}{\mathsf{action}}
\newcommand{\actions}{\mathsf{actions}}
\newcommand{\keys}{\mathsf{keys}}
\newcommand{\data}{\mathsf{data}}
\newcommand{\params}{\mathsf{params}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\reach}{\mathit{\mathit{reach}}}
\newcommand{\hit}{\mathit{hit}}
\newcommand{\reads}{\mathit{reads}}


% commands
\newcommand{\assert}{\mathop{\mathsf{assert}}}
\newcommand{\assume}{\mathop{\mathsf{assume}}}
\newcommand{\apply}{\mathsf{apply}}
\newcommand{\choiceop}{\rotatebox[origin=c]{90}{$\sqsubset\!\!\!\sqsupset$}}
\newcommand{\choice}{\mathbin{\choiceop}}
\DeclareMathOperator*{\bigchoice}{\scalerel*{\choiceop}{\sum}}
\newcommand{\havoc}[1]{\mathop{\textsf{havoc}}#1}
\newcommand{\SKIP}{\mathsf{skip}}

% math
\newcommand{\argmin}{\mathop{\textrm{argmin}}}
\newcommand{\WP}{\textit{wp}}
\newcommand{\satisfy}[3]{({#1,#3}) \models_{#2}}
\newcommand{\notsatisfy}[3]{({#1,#3})\not\models_{#2}}
\newcommand{\nondet}{\mathsf{nondet}}
\newcommand{\ghostly}{\mathsf{ghostly}}
\newcommand{\state}[1]{\llparenthesis#1\rrparenthesis}
\newcommand{\instr}{[?]}
\newcommand{\ginstr}{[\mathghost]}
\newcommand{\qe}{\textsc{Qe}}
\newcommand{\dom}{\textrm{dom}}

% defined functions
\newcommand{\tables}{\mathop{\mathsf{tables}}}

% Theorems
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{conjecture}{Conjecture}
\newtheorem{definition}{Definition}

\begin{document}

\maketitle

\section{Preliminaries}

\subsection{Syntax}

\begin{figure}[htp]
  \[\begin{array}{lclll}
    \multicolumn{3}{l}{\Value} \\
    v & ::= & [n]_w  & \textit{Bitvector Literal} \\
    \multicolumn{3}{l}{\SymbRow} \\
    \rho & ::= & \left\{
    \begin{array}{l}
      \matches = \List[x];\\
      \action = x;\\
      \data = \List[x]
    \end{array}\right\} & \textit{Symbolic Row} \\
    \multicolumn{3}{l}{\BVExpr} \\
    e & ::= & v & \textit{Value} \\
      & \mid & x & \textit{Variable}\\
      & \mid & e \binop e & \textit{Arbitrary Binary Operation}\\
    & \mid & \unop e & \textit{Arbitrary Unary Operation} \\
    \multicolumn{3}{l}{\Table} \\
    t & ::= & \left\{\begin{array}{l}
    t.\id = v; \\
    t.\keys = \List[h.f]; \\
    t.\actions = \List[\lambda \vec x.\,a]\\
    \end{array}\right\} & \textit{Table}\\
    \multicolumn{3}{l}{\BExpr} \\
    b & ::= & \FALSE  & \textit{Absurdity}\\
      & \mid & b \Rightarrow b & \textit{Implication}\\
    & \mid & e = e & \textit{Bitvector Equality}\\
    %% & \mid & \rho \in t & \textit{Table membership}\\
    %% & \mid & \forall \rho.~b & \textit{Row Universality}\\
    \multicolumn{4}{l}{c \in \Cmd, a \in \Action, g \in \GCL, p \in \Prog, \iota \in \Instr } \\
    c & ::=  & h.f := e & \textit{Assignment}\\
      %% & \mid & \havoc \rho & \textit{Row Havoc} & (\iota) \\
      & \mid & \assert b & \textit{Assertion}\\
      & \mid & \assume b & \textit{Assumption} \\
      & \mid & t.\apply() & \textit{Table Application} \\
      & \mid & c;c & \textit{Sequential Composition} \\
      & \mid & c \choice c & \textit{Nondeterministic Choice} \\
      %% & \mid & \{c\} & \textit{Scope} & (g,p,\iota)\\
    \multicolumn{3}{l}{
      \begin{array}{ll}
        x \in \Var & h \in \Hdr\\
        n,w,i \in \mathbb{N} & f \in \Field
    \end{array}} & \textit{Sets }\\
  \end{array}
\]
\caption{Grammar of Commands $c \in \Cmd$.}
\label{fig:grammar}
\end{figure}

The following sections describe aspects of the grammar shown in Figure~\ref{fig:grammar}.

\paragraph{Packets}
Our dataplane programs will reason about structured representations of packets,
that is, they will be transformations on sets of packet headers. In P4 programs,
packet headers $h \in \Hdr$ are essentially structs with fields $f \in \Field$.
Write $h.f$ for a header $h$ and a field $f$ is the value $v$ of $f$ in header
$h$. Our simple command language just treats ``h.f'' as a variable.

\paragraph{Tables}
A table $t \in \Table$ is a record with a few fields described below:
\begin{enumerate}[align=left]
  \item[($t.\id$)] A table's unique identifier. A well-formed program can only have
    one occurence of each table identifier.
  \item[($t.\keys$)] A list of header field accesses indicating the match keys.
  \item[($t.\actions$)] A list of actions that can be executed. An action is a lambda
    expression $\lambda \vec x. c$ where the variables $x$ are in scope for the
    commands $c$, which $c$ are straight-line code only (see below).
\end{enumerate}
For now we assume that the default action is always specified by the controller.
That is, programs never `miss' in tables. See the paragraph on state below. We use $|l|$ to indicate the number of
elements in a list or vector $l$ such as $t.\keys$ or $t.\actions$.

\paragraph{Symbolic Table Rows}
A symbolic table row $\rho \in \SymbRow$ represents a symbolic row. These rows are represented in our programs as simple variables $x$. Like tables,
rows are also records with the following fields \todo{Well formedness constraint?}
\begin{enumerate}[align=left]
  \item[($\rho.\matches$)] A list variable of length representing the possible match keys.
  \item[($\rho.\action$)] A variable representing the action choice
  \item[($\rho.\data$)] A list variable representing the possible action data
\end{enumerate}

To represent the $i$th match variable in $\rho$, use standard list
access notation: $\rho.\matches[i]$.

Note that symbolic table rows are only meant to be used in the instrumentation
stage and not by a programmer.

\paragraph{Values}
Values $v \in \BVExpr$ are bitvector literals, written $[n]_w$, where $n$
is a natural value and $w$ is the width. We say that $[n]_w = [m]_l$ is
undefined if $w \neq l$, and otherwise is true iff $n \equiv m \mod 2^w$.

\paragraph{Bitvector Expressions}
Bitvector expressions $e \in \BVExpr$ can be values $v$, header accesses $h.f$,
symbolic row variables, variables $x$, or any
(currently unspecified) binary or unary bitvector operation.

\paragraph{Boolean Expressions}
Boolean expressions $b \in \BExpr$ can be $\FALSE$, implication ($b_1
\Rightarrow b_2$), equality of bitvector expressions ($e_1 = e_2$ for two
bitvector expressions $e_1$ and $e_2$), or universal quantification $\forall
\rho \in t. b$, where $\rho$ is a symbolic row in table $t$. Note that universal
quantification is meant to only be used by the instrumentation mechanism and not
a programmer.

We can represent other standard boolean operators by using standard encodings:
\[\begin{array}{l}
  \TRUE \triangleq \FALSE \Rightarrow \FALSE \\
  \neg b \triangleq b \Rightarrow \FALSE \\
  b_1 \vee b_2 \triangleq \neg b_1 \Rightarrow b_2 \\
  b_1 \wedge b_2 \triangleq \neg(\neg b_1 \vee \neg b_2) \\
  \vec e = \vec e' \triangleq \bigwedge_i e_i = e'_i
\end{array}\]

\paragraph{Commands}
Data plane programs $c \in \mathsf{Cmd}$ can be assignments ($h.f := e$),
assumptions ($\assume b$), assertions ($\assert b$), table application
($t.\apply()$), sequential composition ($c_1;c_2$ for two commands $c_1$ and $c_2$), and
nondeterministic choice ($c_1 \choice c_2$ for two commands $c_1$ and $c_2$).

We define $\SKIP$ as syntactic sugar for $\assume \TRUE$.

Define $\tables(c) \subset \Table$ to be the set of all tables that occur in $c$.

\subsection{Semantics}

First we describe the semantic objects packet and state before giving semantics
to bitvector expressions, boolean expressions, and commands.

\paragraph{Packets}
A packet $\pkt$ is a map from header fields to values. Use the syntax $\pkt[x
  \mapsto v]$ to represent the packet that is equivalent to $\pkt$ on all variables
fields except $x$, which maps to $v$.

\paragraph{State}
On-switch state is represented by a mapping from tables identifiers $t.\id$ to
lists of rows $[r_1,\ldots,r_n] \in \Row(t)^*$.

A similar to a symbolic row $\rho$, a concrete row $r$ comprises a list of match
values $r.\matches$, an action identifier $r.\action$, and a list of action data
$r.\data$. A concrete row $r$ is in the set $\Row(t)$ if it is well formed for a
table $t$ iff the following conditions hold:
\begin{enumerate}
\item $|r.\matches| = |t.\keys|$
\item $r.\action < |t.\actions|$
\item $|r.\data| = |\vec x|$ where $\lambda \vec x. c = t.\actions[r.\action]$
\end{enumerate}\

A state map $\sigma : \Value \to \Row^*$ is well-formed for a command $c$ iff the
following conditions hold:
\begin{enumerate}[align=left]
\item[(\textsc{Total})] For every $t \in \tables(c)$ $\pkt \in \pkt$ there exists a row $r \in \sigma(t.\id)$ such that $r.matches = \pkt(t.keys)$.
\item[(\textsc{WellFormedRows})] For every $t\in \tables(c)$, every row in $\sigma(t.\id)$ is well-formed.
\item[(\textsc{NoShadow})] For every $t \in \tables(c)$, with $r_1,\ldots,r_n =
  \sigma(t.\id)$, for every $1 \leq i \leq n$, there does not exist $1 \leq j <
  i$ such that $r_i.\matches = r_j.\matches$.
\end{enumerate}

Importantly, we assume that all state is \emph{total}, that is, no packet locally misses
in the table. This is formally defined in Definition~\ref{def:total-state}.

\begin{definition}[Total State]
  \label{def:total-state}
  A state $\sigma$ is total if for every $t \in \dom(\sigma)$, the following
  formula is valid:
  \[\bigwedge_{r \in \sigma(t.\id)} t.\keys = r.\matches \]
\end{definition}

Henceforth we assume that all states are total.



\paragraph{Expressions}
The semantics of expressions is shown in Figure~\label{fig:sem-expr}. Note that
here we implicitly use the strict semantics for definedness, that is, operators
only succeed when all of their arguments are defined, otherwise it returns
undefined.

\begin{figure}[H]
  \[\begin{array}{l>{\triangleq}cl}
  \multicolumn{3}{l}{\edenote{e} : \Pkt \to \Value }\\
    \edenote{v}\pkt &&
    v \\
    \edenote{h.f}\pkt &&
    pkt(h.f)\\
    %% \edenote{\rho.\matches[i]}\pkt &&
    %% \mu(\rho).\matches[i] \\
    %% \edenote{\rho.\action}\pkt &&
    %% \mu(\rho).\action \\
    %% \edenote{\rho.\data[i]} &&
    %% \mu(\rho).\data[i]\\
    \edenote{e_1 \binop e_2}\pkt&&
    \edenote{e_1}\pkt \binop
    \edenote{e_2}\pkt \\
    \edenote{\unop e}\pkt &&
    \unop \left(\edenote{e}\pkt\right)
  \end{array}
  \]
  \caption{Semantics of Expressions}
  \label{fig:sem-expr}
\end{figure}

\paragraph{Boolean Satisfaction}
The satisfaction relation $\pkt \models b$ is defined in
Figure~\ref{fig:bool-satis}. It is completely standard.

\begin{figure}
  \[
  \begin{array}{l >{\iff}c l}
    \pkt \models \FALSE
    && \mathit{never}\\
    \pkt \models b_1 \Rightarrow b_2
    && \pkt \not\models b_1~\mathit{or}~\pkt \models b_2\\
    \pkt \models e_1 = e_2
    && \edenote{e_1}\pkt = \edenote{e_2}\pkt\\

  \end{array}
  \]
  \caption{The satisfaction relation}
  \label{fig:bool-satis}
\end{figure}


\paragraph{Command Evaluation}
Commands are evaluated similar to Avenir in Figure~\ref{fig:com-sem}. The
notable differences are the inclusion of assertions, the nondeterminism
operators, and a cleaner representation of table application.

\begin{figure}[htp]
  \[\begin{array}{r >{\triangleq}cl}
  \multicolumn{3}{l}{\denote{c}^\sigma : \Pkt \to \mathcal{P}(\Pkt)_\error }\\
    \denote{h.f := e}^\sigma\pkt && \{\pkt\{h \mapsto \edenote{e}\pkt\}\} \\
    \denote{\assume b}^\sigma\pkt &&
    \begin{cases}
      \{\pkt\} & \pkt \models b \\
      \{\} & \textit{otherwise} \\
    \end{cases}\\
    \denote{\assert b}^\sigma\pkt &&
    \begin{cases}
      \{\pkt\} & \pkt \models b \\
      \error & \textit{otherwise}
    \end{cases} \\
    %% \denote{\havoc \rho}^\sigma\,\mu\,\pkt &&
    %% \{(\mu\{\rho \mapsto r\}, \pkt) \mid r \in \Row\} \\
    \denote{c_1;c_2}^\sigma\pkt&&
    \bigcup_{\pkt' \in \denote{c_1}^\sigma\pkt}\denote{c_2}^\sigma\pkt' \\
    \denote{c_1 \choice c_2}^\sigma\pkt &&
    \denote{c_1}^\sigma\pkt \cup \denote{c_2}^\sigma\pkt \\
    %% \denote{\{c\}}^\sigma\,\mu\,\pkt &&
    %% \{(\mu,\pkt') \mid (\mu',\pkt') \in \denote{c}^\sigma\,\mu\,\pkt \}\\
    \denote{t.\apply()}^\sigma\,\pkt &&
    \begin{cases}
      \denote{c[\vec d/\vec x]}^\sigma\pkt,
      & \text{where}~\lambda \vec x.~c = r.\action, \vec d = r.\data \\
      & \text{where}~r = \argmin_i\{\pkt \models b_i\} \\
      & \text{where}~b_i = \sigma(t.\id)[i].\matches = t.\keys \\
      \{\pkt\}, & \mathit{otherwise}
    \end{cases}
  \end{array}\]
  \caption{Semantics of Commands}
  \label{fig:com-sem}
\end{figure}

\section{Encoding}

Now we will define a collection of source-to-source translations that deal with
the controller interface.

\subsection{Eliminating Tables}

The first thing to do is to define a source-to-source translation that
eliminates the tables. The observation here is that tables essentially represent
if-else statements, so once we have a state $\sigma$ in hand we can rewrite the
program to a command $c[\sigma] \in \Cmd$ that uses no tables. This translation
is defined in Figure~\ref{fig:table-elim}

\begin{figure}
  \[\begin{array}{r>{\triangleq}cl}
  \multicolumn{3}{l}{(\cdot)[\sigma] : \Cmd \to \Cmd} \\
  (h.f := e)[\sigma] && h.f := e   \\
  (\assume b)[\sigma] && \assume b \\
  (\assert b)[\sigma] && \assert b \\
  (c_1;c_2)[\sigma] && c_1[\sigma];c_2[\sigma] \\
  (c_1 \choice c_2)[\sigma] && c_1[\sigma] \choice c_2[\sigma] \\
  %% (\{c\})[\sigma] && \{c[\sigma]\} \\
  (t.\apply())[\sigma] &&
  \begin{array}[t]{l}
    (\\
    \quad \assume {r_1.\matches = t.\keys};\\
    \quad t.\action[r_1.\action](r_1.\data)\\
    )~\choice\\
    \phantom)~\,\vdots\\
    \phantom)\,\choice~(\\
    \quad \assume {r_n.\matches = t.\keys};\\
    \quad t.\action[r_n.\action](r_n.\data)\\
    )\choice (\\
    \quad \displaystyle \assume {\bigwedge_{i=1}^n r_n.\matches \neq t.\keys};\\
    \quad \SKIP \\
    )\\
    \textrm{where}~[r_1;\ldots;r_n] = \sigma(t.\id)
  \end{array}
  \end{array}
  \]
  \caption{Table Substitution}
  \label{fig:table-elim}
\end{figure}


\begin{theorem}[Table Substitution]
  For every $c \in \Cmd$, well-formed state $\sigma : \Value \to \Row^*$, and
  packet $\pkt \in \Pkt$, then for any state $\tau : \Value \to \Row^*$,
  \[\denote{c}^\sigma\pkt = \denote{c[\sigma]}^\tau\pkt\]
\end{theorem}
\begin{proof}
\todo[inline]{By induction on the structure of $c$.}
\end{proof}


\subsection{Instrumenting Tables}

The next step is to define a source to source translation that eliminates tables
in the absence of concrete table state, which we will write $c\instr \in \Cmd$.
This is the first step towards the goal of constraining control plane behavior.
Want the instrumented program $c\instr$ to fail in exactly the same situations that
$c\instr$ does, however $c\instr$ is constrained to have no table applications.
The only remaining mechanism is to use $\assume$ and $\assert$ statements to
inspect $\sigma$. We define $c[?]$ in Figure~\ref{fig:table-instrument}.

For simplicity, We're going to assume that all actions in a given table have the
same number of action data fields, and each field is the same number of bits.
This can be realized manually.

We augment the headers for a program $c$ with ghost headers $\gamma_t$ for each
table $t \in \tables(c)$. The header $\gamma_t$ has defined fields
$\reach$, which is set to true if the packet reaches table $t$,
$\hit$ which is set to true the packet hits in the table, and
$\reads$ which is really a list of $|t.\keys|$ variables that stores the
values of the packet when evaluating $t.\keys$.

\begin{figure}[htp]
  %% \begin{minipage}[t]{0.5\textwidth}
  %% \[\begin{array}{r >{\triangleq}cl}
  %% \multicolumn{3}{l}{(\cdot)\instr : \Cmd \to \Cmd} \\
  %% (h.f := e)\instr && h.f := e \\
  %% (\assume b)\instr && b \\
  %% (\assert b)\instr && \assert b\\
  %% (c_1;c_2)\instr && c_1\instr;c_2\instr\\
  %% (c_1 \choice c_2)\instr && c_1\instr \choice c_2\instr\\
  %% (\{c\})\instr && \{c\instr\}\\
  %% (t.\apply())\instr && \\
  %% \multicolumn{3}{r}{
  %%   \qquad
  %%   \begin{array}[t]{l} \displaystyle
  %%     \{ \\
  %%     \quad \havoc \rho;\\
  %%     \quad \assume \rho \in t; \\
  %%     \quad \assume \rho.\matches = t.\keys; \\
  %%     \quad \displaystyle \bigchoice_{i=0}^{|t.\action| -1}
  %%     \left(\begin{array}{l}
  %%       \assume \rho.\action = i;\\
  %%       t.\action[i](\rho.\data)
  %%     \end{array}\right)\\
  %%     \} \choice ( \\
  %%     \quad \assume \forall \rho. \rho \in t \Rightarrow \rho.\matches \neq t.\keys;\\
  %%     \quad \SKIP \\
  %%     )
  %%   \end{array}}
  %% \end{array}
  %% \]
  %% \end{minipage}\begin{minipage}[t]{0.45\textwidth}
\[\begin{array}{r >{\triangleq}cl}
  \multicolumn{3}{l}{(\cdot)\instr : \Cmd \to \Cmd} \\
  (h.f := e)\instr && h.f := e \\
  (\assume b)\instr && \assume b \\
  (\assert b)\instr && \assert b\\
  (c_1;c_2)\instr && c_1\instr;c_2\instr\\
  (c_1 \choice c_2)\instr && c_1\instr \choice c_2\instr\\
  (t.\apply())\instr &&\\
  \multicolumn{3}{l}{
    \qquad
    \begin{array}[t]{l} \displaystyle
    \assume \rho_t.\matches = t.\keys; \\
    \displaystyle \bigchoice_{i=0}^{|t.\action| -1}
    \left(\begin{array}{l}
    \assume \rho_t.\action = i;\\
    t.\action[i](\rho_t.\data)
    \end{array}\right)\\
  \end{array}}
  \end{array}
  \]
  \caption{Symbolic Table instrumentation. For simplicity, we
    assume each action in a table has the same number (and types) of parameters}
  \label{fig:table-instrument}
\end{figure}

\begin{figure}[htp]
  \[\begin{array}{r cl}
  \multicolumn{3}{l}{\state\sigma_c : (\Value \to \Row^*) \to \BExpr} \\
  \state\sigma_c &\triangleq
  & \displaystyle\bigwedge_{ t \in \tables(c) }
  \bigvee_{r_i \in \sigma(t.\id)} \rho = r_i
  \end{array}
  \]
  \caption{Symbolic State Encoding}
  \label{fig:table-instrument}
\end{figure}

\begin{samepage}
\begin{theorem}[Instrumentation Equivalence]
  \label{thm:instr-equiv}
  For every $c \in \Cmd$, well-formed state $\sigma : \Value \to \Row^*$, and
  packet $\pkt \in \Pkt$, \[\denote{c}^\sigma\pkt = \denote{\assume
    \state\sigma_c; c\instr}^\sigma\pkt.\]
\end{theorem}
\begin{proof}
\todo[inline]{do the proof}
\end{proof}
\end{samepage}

\subsection{Predicate Semantics}

Now, we would like to be able to translate the result from
Theorem~\ref{thm:instr-equiv} into a
symbolic representation. To do this, we'll use the weakest precondition, defined
in Figure~\ref{fig:wp}

\begin{figure}[H]
  \[
  \begin{array}{r >{\triangleq}c l}
    \WP(h.f := e, b)
    && b[e/h.f] \\
    %% \WP(\havoc \rho, b)
    %% && \forall \rho.\,b \\
    \WP(\assert b_a, b)
    && b_a \wedge b \\
    \WP(\assume b_a, b)
    && b_a \Rightarrow b \\
    \WP(t.\apply,b) && \textrm{\textcolor{red}{undefined}} \\
    \WP(c_1;c_2, b)
    && \WP(c_1,\WP(c_2,b)) \\
    \WP(c_1 \choice c_2, b)
    && \WP(c_1,b) \wedge \WP(c_2,b)
  \end{array}
  \]
  \caption{Dijkstra's weakest precondition function}
  \label{fig:wp}
\end{figure}

Now, we need to relate states $\sigma$ and the computed $\WP(c\instr,\TRUE)$.
Note that since there are no havocs introduced in $c\instr$, all symbolic rows
$\rho$, and header values $h.f$ are unbound.

\begin{conjecture}
  For every $c \in \Cmd$, and $\sigma \in \State$, the following are equivalent:
  \begin{itemize}
  \item \(\state\sigma_c \Rightarrow  \WP(c\instr,\TRUE)\)
  \item \(\WP(c[\sigma], \TRUE)\)
  \end{itemize}
\end{conjecture}



\clearpage
\section{The Research Problem}

Now we can formally define the research problems that we want to solve. We have
an ideal, that is probably not solvable in general. First we begin by defining a control plane formula.

\begin{definition}[Control Plane Formulae ]
  A control plane formula $\varphi$ is a boolean expression in $\BExpr$ that
  contains no header accesses $h.f$.
\end{definition}

\begin{quote}
  \textbf{Inference Problem.} Given a command $c \in \Cmd$, compute (the
  weakest) control plane formula $\varphi$ such that if, for a state $\sigma :
  \Value \to \Row^*$, the following formula is valid \[\state\sigma_c
  \Rightarrow \varphi,\] then \[\forall \pkt \in \Pkt.~ \denote{c}^\sigma\pkt \neq \error \]
\end{quote}

However, this $\varphi$ may be $\FALSE$ for many realistic programs $c$, so we may
prefer to solve the following problem:

\begin{quote}
  \textbf{Repair Problem.} Given a command $c \in \Cmd$, compute (the weakest)
  control plane formula $\varphi$, and a test $b$ such that for every
  packet $\pkt \in \Pkt$ and state $\sigma : \Value \to \Row^*$, if the
  following formula is valid
  \[\state\sigma_c \Rightarrow \varphi,\]
  then \[\denote{\assume b; c}^\sigma\pkt \neq \error \]
\end{quote}

\section{Quantifier Elimination?}

We can observe that \textbf{Inference} is simply solvable by
reduction to Quantifier Elimination. In fact. Quantifier elimination is one of
the key driving forces of the Dilligs' abduction work (\textsc{Hola},
\textsc{Explain}). We sketch the argument here.

\begin{conjecture}[Quantifer Elimination]
  The \textbf{\textrm{Inference Problem}} is reducable to Quantifer Elimination.
\end{conjecture}

\begin{proof}[Proof Sketch.]
  Given a command $c \in \Cmd$. Compute the instrumented command $c\instr$. Let
  $\overrightarrow{h.f}$ describe all the header fields occurring in $c\instr$. Write
  $b[\overrightarrow{h.f}] = \WP(c\instr,\TRUE)$. Observe that $(\forall
  \overrightarrow{h.f}.\;b[\overrightarrow{h.f}]) \Rightarrow
  b[\overrightarrow{h.f}]$ is valid. Then the desired control plane formula is $\qe(\forall \overrightarrow{h.f}.\;b[\overrightarrow{h.f}])$.
\end{proof}

\paragraph{Discussion} This \emph{probably} doesn't work in general. Standard QE procedures are
exponential at best, and enumerating all eth/ipv4 src/dst addresses already
takes an intractable amount of time. It's also not clear (to me) that this
solution is weakest.

The Dilligs' line of work uses Presburger arithmetic QE to implement the
quantifier elimination scheme. We could directly adopt this, however networking
programs make heavy use of bitwise operators like XOR, so we need to take a
different strategy.

\section{Data-Driven Precondition Inference?}


It seems that a solution to our problem can also be found in work by
Padhi/Sharma/Millstein entitled \textit{Data-Driven Precondition Inference with
  Learned Features}\todo{This won't make a ton of sense unless you've
  read this paper}. Their algorithm uses a subroutine,
$\textsc{VPreGen}(c,Q,G)$, which takes code $c$, a boolean predicate $Q$,
and a set of passing test inputs $G$ and produces a predicate $P$ such that
$P(t) = \TRUE$ for all $t \in G$, and $\{P\}\,C\,\{Q\}$.

This gets us most of the way there. Naively, let's consider the space of inputs
to be $\State \times \Pkt$. Then let $b_P$ be a boolean expression such that
$b_p = \textsc{VPreGen}(c\instr,\TRUE,\emptyset)$. Then we know $b_P \Rightarrow
\WP(c\instr,\TRUE)$. However, $b_p$ is not \emph{a priori} a control-plane
formula.

There's a trivial fix: modify the feature learning algorithm to only generate
features that are control-plane formulae. The procedure $\textsc{FeatureLearn}$
generates features from a space of operations described by the procedure
$\textsc{GetOperations}()$. If we simply restrict \textsc{GetOperations} so that
it only returns features that are control-plane formulae, then the generated
expression $b_p$ is guaranteed to be a control plane formula. It may also be
prudent to restrict the input space $G$ to be a subset of $\State$, rather than
of $\State \times \Pkt$, but it doesn't seem strictly necessary.


\paragraph{Discussion} This doesn't quite achieve our goal, because the
synthesized solution is not necessarily the weakest. Further, its not clear to
what extent this procedure relies on a non-empty set of examples $G$. Nor is it
immediately clear where we would get such inputs. Currently each iteration of
the \textsc{VPreGen} algorithm augments the set of examples with a failing
example -- if it turns out that good inputs are necessary, it could be augmented
with a similar solver call to generate a positive example (e.g.
$\textsc{Sat}(\WP(c\instr,\TRUE))$).

\paragraph{Relation to \texttt{bf4}} The \texttt{bf4} algorithm is similar to
\textsc{VPreGen}, using formulae rather than examples. Rather than learn features, \texttt{bf4} uses a static set of
control-plane features (which they call ``atoms''). Then, rather than learn a
candidate boolean expression by abstracting these atoms and using a set of
concrete positive and negative examples, \texttt{bf4} uses Z3's unsat-core to
refine its candidate solution. Finally, \texttt{bf4} is interested in
bug-finding rather than verification so it computes necessary conditions rather
than sufficient conditions. The following table summarizes the differences

\begin{center}
\begin{tabular}{lll}
  \toprule
  & $\textsc{VPreGen}(c,Q,G)$ & \texttt{bf4's} $\textsc{INFER}(G,B,\mathcal P)$ \\
  \midrule \\
  Solution ($\varphi$)
  & $\{\varphi\} C \{Q\}$, and $\forall t \in G.\,\varphi(t)$
  & $G \models \phi$, minimizing(?) $|\{\eta\mid B
  \wedge \varphi\}|$ \\[1.5em]
  Features
  & dynamically learns features
  & features (aka \emph{atoms}) are heuristically defined ($\mathcal P$) \\[1.5em]
  Candidates &
  \begin{tabular}{>{\!\!\!}l}
    abstracts features; \\
    learns boolean expression; \\
    concretizes features
  \end{tabular}
  & iteratively negates Z3's unsat-core\\
  \bottomrule
\end{tabular}
\end{center}

\section{Can we use templates?}

One option is to use a kind of constrained template-based synthesis, where we
generate a catalogue of templates based on syntactic features of the target table.

For example, given a single table like the following:

\[t = \{\keys: [h.f]; \actions: [\lambda x.~~h.g:= x]\}\]

and the simple program \[t.\apply()\]

We may be able to generate a boolean template constructed from the following
comparisons

\[
\begin{array}{l}
  \rho.\keys[i]~\square_{\{=,\neq\}}~?_{v_3} \Rightarrow \rho.\data[i]~\square_{\{=,\neq\}}~?_{v_4} \\

  \rho.\keys[i]~\square_{\{=,\neq\}}\rho.\data[i]
\end{array}\]

where $[b]?$ indicates a hole to either use template $b$ or replace it with
$\TRUE$, $\square_S$ indicates a template for an operation, where $S$ is the set
of allowed operations, and $?_{v_i}$ indicates a hole that should evaluate to an element
of $\Value$.



Now we may wonder: \emph{can we procedurally generate templates in a (nearly) complete way}?

To do so, we need to extend our templates along the following dimensions:
\begin{enumerate}[align=left]
\item[\textit{Keys}.] Should generalize by changing the LHS comparisons to $
  \bigwedge_i[\rho.\keys[i]~\square_{\{=,\neq\}}~?_{v_i}]?$
\item[\textit{Action Data}.] Should generalize by changing the RHS comparisons to $\bigwedge_i[\rho.\data[i]~\square_{\{=,\neq\}}~?_{v_i}]?$
\item[\textbf{Actions}.] We need to generalize the template across multiple actions. This should be as simple as adding $\rho.\action = i$ on the RHS of each implication above.
\item[\textit{Sequence}.] I'm not sure how to generalize sequentially composed tables.
  Perhaps a larger catalogue of templates conditioned on structural information:
  if we notice that $t_1$ has a dataflow path to the keys of $t_2$, we should
  generate a join condition template, otherwise we may be able to simply ``and'' the templates.

\item[\textit{Nondeterminism} ($c_1 \choice c_2$).] To solve the
  \textbf{Inference Problem} we simply `and' the templates together, but to solve
  the \textbf{Repair Problem} we may be able to constrain the problem (by
  constraining the packets) to either $c_1$ or $c_2$. This would require
  computing a $b_{\textit{pkt}}$.
\end{enumerate}

\end{document}
